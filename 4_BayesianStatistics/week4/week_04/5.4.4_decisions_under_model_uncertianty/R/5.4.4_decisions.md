decision making under uncertainty
================

Load the data and preprocess

``` r
library(MASS)
data(UScrime)

#Log transform all continuous variables except `So` which is in column 2. 
# We're overwriting the dataframe in this case.

UScrime[,-2] = log(UScrime[,-2])
```

### Run BAS

I am going to run `BAS` using the sampling without replacement option to enumerate all 2<sup>15</sup> models.

``` r
library(BAS)
crime.ZS =  bas.lm(y ~ ., 
                   data=UScrime,
                   prior="ZS-null",
                   modelprior=uniform()) 
```

**Model Choice**

`BAS` has methods defined to return fitted values, `fitted`, using the observed design matrix and predictions at either the observed data or potentially new values, `predict`, as with `lm`.

``` r
muhat.BMA = fitted(crime.ZS, estimator="BMA")
BMA  = predict(crime.ZS, estimator="BMA")

# predict has additional slots for fitted values under BMA, predictions under each model
names(BMA)
```

    ##  [1] "fit"         "Ybma"        "Ypred"       "postprobs"   "se.fit"     
    ##  [6] "se.pred"     "se.bma.fit"  "se.bma.pred" "df"          "best"       
    ## [11] "bestmodel"   "prediction"  "estimator"

Plotting the two sets of fitted values,

``` r
par(mar=c(9, 9, 3, 3))
plot(muhat.BMA, BMA$fit, 
     pch=16, col=myblue,
     xlab=expression(hat(mu[i])), ylab=expression(hat(Y[i])))
abline(0,1)
```

![](5.4.4_decisions_files/figure-markdown_github/unnamed-chunk-1-1.png) we see that they are in perfect agreement. That is always the case as the posterior mean for the regression mean function at a point *x* is the expected posterior predictive value for *Y* at *x*. This is true not only for estimators such as BMA, but the expected values under model selection.

### Inference with model selection

In addition to using BMA, we can use the posterior means under model selection. This corresponds to a decision rule that combines estimation and selection. `BAS` currently implements the following options

**highest probability model:**

``` r
HPM = predict(crime.ZS, estimator="HPM")

# show the indices of variables in the best model where 0 is the intercept
HPM$bestmodel
```

    ## [1]  0  1  3  4  9 11 13 14 15

A little more interpretable version with names:

``` r
(crime.ZS$namesx[HPM$bestmodel +1])[-1]
```

    ## [1] "M"    "Ed"   "Po1"  "NW"   "U2"   "Ineq" "Prob" "Time"

This model is stored in the output in position 15535 and can be extracted as

``` r
HPM$best
```

    ## [1] 15535

If we wanted to find the coefficients for this model for example, we could use the following:

``` r
crime.coef.ZS = coef(crime.ZS)
crime.coef.ZS$conditionalmeans[HPM$best,]
```

    ##    Intercept            M           So           Ed          Po1 
    ##  6.724936198  0.000000000  0.000000000  0.000000000  0.000000000 
    ##          Po2           LF          M.F          Pop           NW 
    ##  1.096087491  0.561077925  0.511624181 -0.081893298  0.000000000 
    ##           U1           U2          GDP         Ineq         Prob 
    ## -0.175111752  0.180288161  0.590021604  1.814493253 -0.183138582 
    ##         Time 
    ## -0.009996075

``` r
crime.coef.ZS$conditionalsd[HPM$best,]
```

    ##  Intercept          M         So         Ed        Po1        Po2 
    ## 0.03450765 0.00000000 0.00000000 0.00000000 0.00000000 0.21375186 
    ##         LF        M.F        Pop         NW         U1         U2 
    ## 0.72529274 2.21725633 0.05965829 0.00000000 0.36423042 0.25612253 
    ##        GDP       Ineq       Prob       Time 
    ## 0.46020856 0.40826918 0.11009802 0.20392442

to extract the posterior means and posterior standard deviations of the coefficients of the highest probability model.

**median probability model:**

``` r
MPM = predict(crime.ZS, estimator="MPM")
attr(MPM$fit, 'model')
```

    ## [1]  0  1  3  4  9 11 13 14

``` r
(crime.ZS$namesx[attr(MPM$fit, 'model') +1])[-1]
```

    ## [1] "M"    "Ed"   "Po1"  "NW"   "U2"   "Ineq" "Prob"

Note that we can also extract the best model from the attribute in the fitted values as well.

For obtaining fitted or predicted values, the media probability model may not be part of the sample (in the general case without enumeration) so the fitted and predict code in BAS actually just refits this model initializing BAS at this model. Here is actually what is under the hood in case you wanted to find coefficients for the MPM.

``` r
crime.MPM = bas.lm(y ~ ., 
                   data=UScrime,
                   prior="ZS-null",
                   modelprior=uniform(),
                   bestmodel=crime.ZS$probne0 > .5, n.models=1) 
```

The logical condition `crime.ZS$probne0` provides a vector of length 16 of the inclusion indicators of the median probabilty model, e.g. where the probabilty that the coefficient is not 0 is greater than 0.5. The option `n.models = 1` fits just this model.

Using the `coef` function applied to just this model we can extract the coefficients for the HPM model:

``` r
coef(crime.MPM)
```

    ## 
    ##  Marginal Posterior Summaries of Coefficients: 
    ## 
    ##  Using  BMA 
    ## 
    ##  Based on the top  1 models 
    ##            post mean  post SD   post p(B != 0)
    ## Intercept   6.72494    0.02713   1.00000      
    ## M           1.46180    0.43727   1.00000      
    ## So          0.00000    0.00000   0.00000      
    ## Ed          2.30642    0.43727   1.00000      
    ## Po1         0.87886    0.16204   1.00000      
    ## Po2         0.00000    0.00000   0.00000      
    ## LF          0.00000    0.00000   0.00000      
    ## M.F         0.00000    0.00000   0.00000      
    ## Pop         0.00000    0.00000   0.00000      
    ## NW          0.08162    0.03743   1.00000      
    ## U1          0.00000    0.00000   0.00000      
    ## U2          0.31053    0.12816   1.00000      
    ## GDP         0.00000    0.00000   0.00000      
    ## Ineq        1.18815    0.28710   1.00000      
    ## Prob       -0.18401    0.06466   1.00000      
    ## Time        0.00000    0.00000   0.00000

**best predictive model:**

This is the model that is closest to BMA predictions under squared error loss.

``` r
BPM = predict(crime.ZS, estimator="BPM")
(crime.ZS$namesx[attr(BPM$fit, 'model') +1])[-1]
```

    ##  [1] "M"    "So"   "Ed"   "Po1"  "Po2"  "M.F"  "NW"   "U2"   "Ineq" "Prob"

Let's see how they compare:

``` r
myblue = rgb(86,155,189, name="myblue", max=256)
mydarkgrey = rgb(.5,.5,.5, name="mydarkgrey", max=1)
par(cex=1.8, cex.axis=1.8, cex.lab=2, mfrow=c(2,2), mar=c(5, 5, 3, 3), col.lab=mydarkgrey, col.axis=mydarkgrey, col=mydarkgrey)
library(GGally)
ggpairs(data.frame(HPM = as.vector(HPM$fit),  #this used predict so we need to extract fitted values
                   MPM = as.vector(MPM$fit),  # this used fitted
                   BPM = as.vector(BPM$fit),  # this used fitted
                   BMA = as.vector(BMA$fit))) # this used predict
```

![](5.4.4_decisions_files/figure-markdown_github/unnamed-chunk-6-1.png)

Using the `se.fit = TRUE` option with `predict` we can also calculate standard deviations for prediction or for the mean and use this as imput for the `confint` function for the prediction object.

``` r
BPM = predict(crime.ZS, estimator="BPM", se.fit=TRUE)
crime.conf.fit = confint(BPM, parm="mean")
crime.conf.pred = confint(BPM, parm="pred")
cbind(BPM$fit, crime.conf.fit, crime.conf.pred)
```

    ##                  2.5  %  97.5  %     mean   2.5  %  97.5  %     pred
    ##  [1,] 6.668988 6.513238 6.824738 6.668988 6.258715 7.079261 6.668988
    ##  [2,] 7.290854 7.151787 7.429921 7.290854 6.886619 7.695089 7.290854
    ##  [3,] 6.202166 6.039978 6.364354 6.202166 5.789406 6.614926 6.202166
    ##  [4,] 7.661307 7.490608 7.832006 7.661307 7.245129 8.077484 7.661307
    ##  [5,] 7.015570 6.847647 7.183493 7.015570 6.600523 7.430617 7.015570
    ##  [6,] 6.469547 6.279276 6.659818 6.469547 6.044966 6.894128 6.469547
    ##  [7,] 6.776133 6.555130 6.997135 6.776133 6.336920 7.215346 6.776133
    ##  [8,] 7.299560 7.117166 7.481955 7.299560 6.878450 7.720670 7.299560
    ##  [9,] 6.614927 6.482384 6.747470 6.614927 6.212890 7.016964 6.614927
    ## [10,] 6.596912 6.468988 6.724836 6.596912 6.196374 6.997449 6.596912
    ## [11,] 7.032834 6.877582 7.188087 7.032834 6.622750 7.442918 7.032834
    ## [12,] 6.581822 6.462326 6.701317 6.581822 6.183896 6.979748 6.581822
    ## [13,] 6.467921 6.281998 6.653843 6.467921 6.045271 6.890571 6.467921
    ## [14,] 6.566239 6.403813 6.728664 6.566239 6.153385 6.979092 6.566239
    ## [15,] 6.550129 6.388987 6.711270 6.550129 6.137779 6.962479 6.550129
    ## [16,] 6.888592 6.746097 7.031087 6.888592 6.483166 7.294019 6.888592
    ## [17,] 6.252735 6.063944 6.441526 6.252735 5.828815 6.676654 6.252735
    ## [18,] 6.795764 6.564634 7.026895 6.795764 6.351369 7.240160 6.795764
    ## [19,] 6.945687 6.766289 7.125086 6.945687 6.525866 7.365508 6.945687
    ## [20,] 7.000331 6.840374 7.160289 7.000331 6.588442 7.412220 7.000331
    ## [21,] 6.613748 6.443389 6.784108 6.613748 6.197710 7.029787 6.613748
    ## [22,] 6.509534 6.352123 6.666946 6.509534 6.098628 6.920441 6.509534
    ## [23,] 6.781430 6.589687 6.973172 6.781430 6.356187 7.206672 6.781430
    ## [24,] 6.801865 6.659905 6.943825 6.801865 6.396626 7.207104 6.801865
    ## [25,] 6.368493 6.187973 6.549014 6.368493 5.948191 6.788795 6.368493
    ## [26,] 7.406220 7.173560 7.638879 7.406220 6.961027 7.851412 7.406220
    ## [27,] 5.995056 5.780243 6.209869 5.995056 5.558924 6.431187 5.995056
    ## [28,] 7.130996 6.970370 7.291621 7.130996 6.718847 7.543144 7.130996
    ## [29,] 7.084303 6.904331 7.264275 7.084303 6.664237 7.504370 7.084303
    ## [30,] 6.519208 6.360876 6.677539 6.519208 6.107948 6.930468 6.519208
    ## [31,] 6.191546 5.952977 6.430114 6.191546 5.743237 6.639854 6.191546
    ## [32,] 6.646586 6.472328 6.820844 6.646586 6.228936 7.064236 6.646586
    ## [33,] 6.778853 6.591383 6.966323 6.778853 6.355520 7.202186 6.778853
    ## [34,] 6.813627 6.683297 6.943958 6.813627 6.412314 7.214940 6.813627
    ## [35,] 6.686652 6.503099 6.870205 6.686652 6.265039 7.108265 6.686652
    ## [36,] 7.046639 6.788852 7.304426 7.046639 6.587815 7.505464 7.046639
    ## [37,] 6.786861 6.601977 6.971745 6.786861 6.364667 7.209055 6.786861
    ## [38,] 6.306094 6.128026 6.484162 6.306094 5.886840 6.725348 6.306094
    ## [39,] 6.600676 6.460387 6.740965 6.600676 6.196020 7.005333 6.600676
    ## [40,] 7.094493 6.934796 7.254189 7.094493 6.682705 7.506280 7.094493
    ## [41,] 6.595673 6.374613 6.816734 6.595673 6.156431 7.034916 6.595673
    ## [42,] 6.005732 5.761671 6.249794 6.005732 5.554476 6.456988 6.005732
    ## [43,] 6.962800 6.822918 7.102682 6.962800 6.558285 7.367316 6.962800
    ## [44,] 7.065421 6.910261 7.220580 7.065421 6.655371 7.475470 7.065421
    ## [45,] 6.266709 6.060228 6.473190 6.266709 5.834621 6.698797 6.266709
    ## [46,] 6.511698 6.315350 6.708046 6.511698 6.084359 6.939037 6.511698
    ## [47,] 6.823072 6.644370 7.001773 6.823072 6.403548 7.242596 6.823072

Finding the coefficients of the BPM is similar to the HPM:

``` r
# location of BPM;

BPM$best
```

    ## [1] 29420

``` r
crime.coef.ZS$conditionalmeans[BPM$best,]
```

    ##   Intercept           M          So          Ed         Po1         Po2 
    ##  6.72493620  0.00000000  0.00000000 -0.64101375  1.21140899 -0.38067570 
    ##          LF         M.F         Pop          NW          U1          U2 
    ##  0.81685748  0.00000000 -0.01947855  0.00000000  0.00000000  0.00000000 
    ##         GDP        Ineq        Prob        Time 
    ##  0.00000000  0.00000000 -0.02703139  0.09892928

``` r
crime.coef.ZS$conditionalsd[BPM$best,]
```

    ##  Intercept          M         So         Ed        Po1        Po2 
    ## 0.04658203 0.00000000 0.00000000 0.69852507 1.25078643 1.25642458 
    ##         LF        M.F        Pop         NW         U1         U2 
    ## 0.79821513 0.00000000 0.06163702 0.00000000 0.00000000 0.00000000 
    ##        GDP       Ineq       Prob       Time 
    ## 0.00000000 0.00000000 0.13938706 0.27151929

Note that this model conditional on the choice of `X` used for fitting or prediction in deciding which is best in the code.

------------------------------------------------------------------------

From the output we can ask which state has the highest predicted crime rate? the lowest?

``` r
# lowest 
best = which.min(BPM$fit)
crime.ZS$X[best, BPM$bestmodel]
```

    ## (Intercept)           M          So          Ed         Po1          LF 
    ##    1.000000    4.905275    0.000000    4.691348    4.234107    6.291569 
    ##         Pop          U1         GDP        Ineq 
    ##    1.791759    4.382027    6.335054    4.934474

What characteristics lead to the lowest rates? (where do the X values fall in the distribution of the covariantes - are they at the extremes?)

### Prediction with a new data set

Using the `newdata` option as with the `predict` function in `lm`, you can predict at new values of the covariates (OK in this case the data frame is the same, so it is the same as the insample prediction). The code below illustrates using BMA and Monte Carlo simulation to obtain the intervals.

``` r
BMA = predict(crime.ZS, UScrime, estimator="BMA", se.fit=TRUE, nsim=10000)
crime.conf.fit = confint(BMA, parm="mean")
crime.conf.pred = confint(BMA, parm="pred")
cbind(BPM$fit, crime.conf.fit, crime.conf.pred)
```

    ##                  2.5  %  97.5  %     mean   2.5  %  97.5  %     pred
    ##  [1,] 6.668988 6.507544 6.812778 6.661770 6.244253 7.081233 6.661770
    ##  [2,] 7.290854 7.131367 7.455849 7.298827 6.879105 7.715011 7.298827
    ##  [3,] 6.202166 5.946725 6.400289 6.179308 5.741296 6.620290 6.179308
    ##  [4,] 7.661307 7.365332 7.818540 7.610585 7.139015 8.052799 7.610585
    ##  [5,] 7.015570 6.855286 7.263456 7.054238 6.614592 7.488275 7.054238
    ##  [6,] 6.469547 6.286612 6.738178 6.514064 6.076576 6.976017 6.514064
    ##  [7,] 6.776133 6.504020 7.072249 6.784846 6.302282 7.268403 6.784846
    ##  [8,] 7.299560 7.045253 7.484919 7.266344 6.851607 7.722926 7.266344
    ##  [9,] 6.614927 6.481920 6.780227 6.629448 6.210018 7.047601 6.629448
    ## [10,] 6.596912 6.467755 6.739675 6.601246 6.189749 7.014380 6.601246
    ## [11,] 7.032834 6.871870 7.240846 7.055003 6.608989 7.472517 7.055003
    ## [12,] 6.581822 6.417969 6.717886 6.570625 6.188107 7.012919 6.570625
    ## [13,] 6.467921 6.206863 6.714203 6.472327 6.016392 6.940559 6.472327
    ## [14,] 6.566239 6.390911 6.762856 6.582374 6.168567 7.033827 6.582374
    ## [15,] 6.550129 6.362364 6.755610 6.556880 6.134521 7.011584 6.556880
    ## [16,] 6.888592 6.750652 7.064157 6.905017 6.500721 7.322976 6.905017
    ## [17,] 6.252735 5.985192 6.468567 6.229073 5.781796 6.690510 6.229073
    ## [18,] 6.795764 6.550813 7.104049 6.809572 6.346863 7.307052 6.809572
    ## [19,] 6.945687 6.752104 7.138272 6.943294 6.514555 7.378570 6.943294
    ## [20,] 7.000331 6.784671 7.148272 6.961980 6.526159 7.371089 6.961980
    ## [21,] 6.613748 6.400854 6.817961 6.608947 6.142519 7.029318 6.608947
    ## [22,] 6.509534 6.182134 6.656503 6.429088 5.985522 6.891112 6.429088
    ## [23,] 6.781430 6.688119 7.107181 6.898828 6.458671 7.342743 6.898828
    ## [24,] 6.801865 6.604071 6.955083 6.777130 6.351201 7.192893 6.777130
    ## [25,] 6.368493 6.212601 6.603217 6.405741 5.974275 6.830719 6.405741
    ## [26,] 7.406220 7.142410 7.659397 7.401082 6.935112 7.864732 7.401082
    ## [27,] 5.995056 5.773446 6.260106 6.019651 5.559414 6.478268 6.019651
    ## [28,] 7.130996 6.957862 7.345498 7.156541 6.703153 7.586280 7.156541
    ## [29,] 7.084303 6.872946 7.313250 7.089698 6.646057 7.537531 7.089698
    ## [30,] 6.519208 6.315827 6.688571 6.500233 6.083094 6.935347 6.500233
    ## [31,] 6.191546 5.994095 6.419194 6.208963 5.756053 6.651470 6.208963
    ## [32,] 6.646586 6.410980 6.794754 6.605944 6.170489 7.039645 6.605944
    ## [33,] 6.778853 6.628303 6.968756 6.798139 6.395057 7.221255 6.798139
    ## [34,] 6.813627 6.692380 6.952803 6.820052 6.407332 7.219392 6.820052
    ## [35,] 6.686652 6.433430 6.832177 6.625465 6.192023 7.063000 6.625465
    ## [36,] 7.046639 6.706712 7.329635 7.029051 6.511245 7.522464 7.029051
    ## [37,] 6.786861 6.544920 7.015324 6.794004 6.365540 7.273960 6.794004
    ## [38,] 6.306094 6.142864 6.594460 6.363691 5.935206 6.853799 6.363691
    ## [39,] 6.600676 6.455862 6.735281 6.603108 6.182560 6.994217 6.603108
    ## [40,] 7.094493 6.879691 7.212636 7.044736 6.639375 7.476026 7.044736
    ## [41,] 6.595673 6.310977 6.788307 6.548160 6.083993 7.011571 6.548160
    ## [42,] 6.005732 5.753184 6.334691 6.046124 5.564918 6.534409 6.046124
    ## [43,] 6.962800 6.747467 7.117345 6.929741 6.516419 7.382303 6.929741
    ## [44,] 7.065421 6.833399 7.175776 7.006019 6.585208 7.437180 7.006019
    ## [45,] 6.266709 6.001748 6.479365 6.236002 5.769041 6.677940 6.236002
    ## [46,] 6.511698 6.368297 6.861139 6.608591 6.169054 7.085798 6.608591
    ## [47,] 6.823072 6.653034 7.012763 6.830450 6.392923 7.268916 6.830450
