---
title: "Bayesian modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(statsr)
library(BAS)
library(lubridate)
library(ggcorrplot)
source('multiplot.r')
```

### Load data



```{r load-data}
load("movies.Rdata")
str(movies)
```


* * *

## Part 1: Data

*Describe how the observations in the sample are collected, and the implications of this data collection method on the scope of inference (generalizability / causality).*


This dataset, as described in the instructions does consist in a **random sample** of **651 US movies** extracted from both **IMDB** and **Rotten Tomatoes** databases.
```{r}
summary(movies$thtr_rel_year)
ggplot(data = movies, aes(x = thtr_rel_year))+ geom_bar() + ggtitle("Theater release year of dataset")
```

All have been released between 1970 and 2014. 

Assuming this is an observational study with random sampling, it should be *representative* of US movies. By using random sampling, the resulting prediction model should be *generalizable* to US movies released between 1970 and 2014.




#### Remark regarding generalizability *(out of scope)*

In order to get an idea whether the random sample is generalizable, i compared it with a larger IMDB titles dataset ( *imdb_official_titles.csv* 236,710 different movies) and focused on the **release year distribution**.

I filtered this imdb dataset on the same time period as the movies dataset :

```{r}

min_tht_release_year <- min(movies$thtr_rel_year)
max_tht_release_year<- max(movies$thtr_rel_year)
imdb_titles<-read.csv('imdb_official_titles.csv')
sample_imdb_titles<-sample_n(imdb_titles[(imdb_titles$year>=min_tht_release_year) &
 (imdb_titles$year<=max_tht_release_year),],nrow(movies))

both_datasets<-data.frame(movies$thtr_rel_year,sample_imdb_titles$year)
colnames(both_datasets) <- c("movies","imdb_sample")
both_datasets<-both_datasets %>% gather('dataset','release_year')

ggplot(data=both_datasets,aes(x=release_year,fill=dataset))+geom_histogram(position="identity",alpha=0.3)

```


Both *movies* and *imdb sample* datasets are not normally distributed as shown with the test below :
```{r}
shapiro.test(movies$thtr_rel_year)
shapiro.test(sample_imdb_titles$year)
```
I then  used the Kolmogorvo-Smirnov test to check if both theater release years are equally distributed.

```{r}
ks.test(movies$thtr_rel_year,sample_imdb_titles$year)
```
A qqplot does confirm this result :
```{r}
qqplot(movies$thtr_rel_year,sample_imdb_titles$year)
```

Although the *movies* dataset is a random sample, i cast doubts on the generalizability of such sample.


#### Causality
As we are in a context of **observational studies**, we might conclude some association patterns, but contrary to an experimental study with random samples,  **no causality** that might be deduced from it.


* * *

## Part 2: Data manipulation

*Create new variables using the mutate function in the dplyr package following these guidelines:*

*Create new variable based on `title_type`:*
*- New variable should be called `feature_film` with levels yes (movies that are feature films) and no (2 pt)*
 
```{r}
movies<-movies %>% mutate(feature_film = if_else(movies$title_type=='Feature Film','yes','no') ) %>% mutate(feature_film = as.factor(feature_film))
```

*Create new variable based on `genre`: *
*- New variable should be called `drama` with levels yes (movies that are dramas) and no (2 pt)*
```{r}
movies<-movies %>% mutate(drama = if_else(movies$genre=='Drama','yes','no'))%>% mutate(drama = as.factor(drama))
```

*Create new variable based on `mpaa_rating`: *
*- New variable should be called `mpaa_rating_R` with levels yes (movies that are R rated) and no (2 pt)*
```{r}
movies<-movies %>% mutate(mpaa_rating_R = if_else(movies$mpaa_rating=='R','yes','no'))%>% mutate(mpaa_rating_R = as.factor(mpaa_rating_R))
```


*Create two new variables based on `thtr_rel_month`:*
*- New variable called `oscar_season` with levels yes (if movie is released in November, October, or December) and no (2 pt)*
```{r}
movies<-movies %>% mutate(oscar_season = if_else(movies$thtr_rel_month>9,'yes','no'))%>% mutate(oscar_season = as.factor(oscar_season))
```

*- New variable called `summer_season` with levels yes (if movie is released in May, June, July, or August) and no (2 pt)*
```{r}
movies<-movies %>% mutate(summer_season = if_else((movies$thtr_rel_month>4)&(movies$thtr_rel_month<9),'yes','no'))%>% mutate(summer_season = as.factor(summer_season))
```




* * *

## Part 3: Exploratory data analysis

*Perform exploratory data analysis (EDA) of the relationship between audience_score and the new variables constructed in the previous part. Your EDA should contain numerical summaries and visualizations. This might mean you initially create a lot more visualizations and summary statistics than what you finally choose to include in your paper. Each R output and plot should be accompanied by a brief interpretation.*



Let's store the newly created variables in a vector :

```{r}
new_vars = c('feature_film','drama','mpaa_rating_R','oscar_season','summer_season')
```


We can draw a correlogramm of the selected variables :

```{r}

movies_selected_var<- movies %>% select(one_of(new_vars)) %>% mutate_each(funs(ifelse(. == 'no', 0,1)))
movies_selected_var$audience_score <- movies$audience_score


corr <- round(cor(movies_selected_var),3)
ggcorrplot(corr, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlogram of Selected variables", 
           ggtheme=theme_bw)
```

+ The *feature_film* variable is the most correlated (negatively) with our target parameter *audience_score*.
+ *summer_season* and *oscar_season* are quite correlated (Pearson = -0.44), which could produce **multicollinearity.**
+ There is a slight positive correlation between *drama* and *audience_score.*



Then, let's create a standard function to compute the comparison between *audience_score* and the newly created variables :
```{r}

compute_relationship <- function(movies,new_var){
  p0<-ggplot(data=movies,aes_string(y="audience_score",x=new_var,col=new_var)) + geom_boxplot() + theme(legend.position="none")
  groupy<-movies %>% group_by_("thtr_rel_year",new_var) %>% summarise(average_audience_score=mean(audience_score))
  p1<-ggplot(groupy,aes_string(x="thtr_rel_year",y="average_audience_score",col=new_var))+ geom_point()
  
  p2<-ggplot(data=movies,aes_string(x="audience_score",fill=new_var))+geom_histogram(bins=100,position="identity",alpha=0.5)+ guides(fill=FALSE)
  layout <- matrix(c(1,3,2,2), nrow = 2, byrow = TRUE)
  multiplot(p0, p1,p2, cols=2,layout=layout)
}

```


We focus on the new variables with an absolute Pearson correlation **higher than 0.1**.

#### feature_film

```{r}
compute_relationship(movies,"feature_film")
```

+ We notice that the non-feature film are almost all above the the average_score, and regardless the years.
+ This confirms the relatively high correlation between this variable and audience_score. 
+ It will be interesting to see the posterior probability of inclusion of this variable in the top 5 regression models.


#### drama

```{r}
compute_relationship(movies,"drama")
```

For drama movies, though above the others genre, the average audience_score is decreasing as years go by. 

* * *

## Part 4: Modeling

*Develop a Bayesian regression model to predict `audience_score` from the following explanatory variables. Note that some of these variables are in the original dataset provided, and others are new variables you constructed earlier:`feature_film`,` drama`, `runtime`, `mpaa_rating_R`, `thtr_rel_year`, `oscar_season`, `summer_season`, `imdb_rating`, `imdb_num_votes`, `critics_score`, `best_pic_nom`, `best_pic_win`, `best_actor_win`, `best_actress_win`, `best_dir_win`, `top200_box`. Complete Bayesian model selection and report the final model. Also perform model diagnostics and interpret coefficients of your final model in context of the data.*

First, we generate a new dataset based on the listed variables :
```{r}
features<- c("audience_score", "feature_film","drama", "runtime", "mpaa_rating_R", "thtr_rel_year", "oscar_season", "summer_season", "imdb_rating", "imdb_num_votes", "critics_score", "best_pic_nom", "best_pic_win", "best_actor_win", "best_actress_win", "best_dir_win", "top200_box")

movies_with_features<- movies %>% select(one_of(features))
```

Let's plot a correlogram of the selected features :
```{r}
movies_all_numeric <- movies_with_features %>% mutate_if(is.factor,as.numeric) %>% na.omit()

corr <- round(cor(movies_all_numeric),2)
ggcorrplot(corr, hc.order = FALSE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 2, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlogram of all features", 
           ggtheme=theme_bw)
```

Without a model, we can observe that the heavy predictors for audience_score are unsurprisingly imdb_rating (0.86) and critics_score (0.7)
They dwarf all the newly variables.


let's start with a Bayesian regression model using all selected features :
I use the Zellner-Siow Cauchy prior for this model, with a Markov chain Monte Carlo method.

```{r}
movies_no_na = na.omit(movies_with_features)
movies.ZS = bas.lm(audience_score ~ . -audience_score, data = movies_no_na,
                   prior = "ZS-null", 
                   modelprior = uniform(),
                   method = 'MCMC')
movies.ZS
```

The result above does confirm our assumption : no model without imdb_rating and critics_score.


We can now check whether the Markov chain Monte Carlo simulation has runned long enough :
```{r}
diagnostics(movies.ZS)
```

Yes, indeed, for both plots we get a line : the MCMC simulation did run long enough.



We can see the top 5 models selected by our Bayesian regressor :
```{r}
summary(movies.ZS)
```
The resulting determination coefficients R2 are quite good, above 0.75, which is not a suprise given the strongly correlated predictors **imdb_rating** and **critics_score**.

Amongst the newly created variable, only *mpaa_rating_R* has been selected twice within the top 5 models.


Now, let's proceed to a step by step analysis of the generated model :

First, we plot the spread of the residuals along the audience_score :

```{r}
plot(movies.ZS,which=1,add.smooth=T)
```

What we notice here are two elements :

- the movies with an effective low audience (from 0% to 35%) score are over-rated by the model.

- from 40% to 70% the opposite occurs.


That's **not a good result**, residuals should be uniformly spread. We should considere as outliers the low-rated films.



```{r}
plot(movies.ZS,which=2,add.smooth=T)
```

After 2000 models built, we reach a plateau, and no more probability is significantly added.

```{r}

plot(movies.ZS,which=3,add.smooth=T)
```

The best models (i.e with the highest marginal likelihood) are in the range of 2 to 4 predictors.

```{r}

plot(movies.ZS,which=4,add.smooth=T)
```

Finally, this plot confirms our first assumption : only imdb_rating and critics_score are relevant predictors for audience_score.





```{r}
image(movies.ZS,rotate = F)
```





* * *

## Part 5: Prediction

Moonlight

```{r}
moonlight_df<-data.frame('runtime'=110, 'imdb_rating'=7.6,'critics_score'=.97, "feature_film"=as.factor('yes'),"drama"=as.factor('yes'),  "mpaa_rating_R"=as.factor('no'), "thtr_rel_year"=2016, "oscar_season"=as.factor('no'), "summer_season"=as.factor('no'), "imdb_num_votes"=115403,  "best_pic_nom"=as.factor('no'), "best_pic_win"=as.factor('no'), "best_actor_win"=as.factor('no'), "best_actress_win"=as.factor('no'), "best_dir_win"=as.factor('yes'), "top200_box"=as.factor('yes'),'audience_score'=0)

df_with_prediction<- rbind(movies_with_features,moonlight_df)


BMA = predict(movies.ZS, newdata=df_with_prediction[nrow(df_with_prediction),], estimator="BMA", se.fit=TRUE, nsim=10000)
print('BMA')
BMA$fit

HPM = predict(movies.ZS, newdata=df_with_prediction[100:105,], estimator="HPM", se.fit=TRUE, nsim=10000)
print('HPM')
HPM$fit

MPM = predict(movies.ZS, newdata=df_with_prediction[100:105,,], estimator="MPM", se.fit=TRUE, nsim=10000)
print('MPM')
MPM$fit

BPM = predict(movies.ZS, newdata=df_with_prediction[100:105,,], estimator="BPM", se.fit=TRUE, nsim=10000)
print ('BPM')
BPM$fit

```

```{r}
library(BAS)
set.seed(42)

d <- data.frame(
  likes.cats = c(rep("yes", 60), rep("no", 40)),
  likes.dogs = c(rep("yes", 30), rep("no", 70)),
  fish.eaten.per.year = c(rnorm(100, mean=20, sd=5)),
  donated.to.cats = c(rnorm(50, mean=50, sd=10), rep(0, 50))
)

m <- bas.lm(donated.to.cats ~ likes.cats + likes.dogs + fish.eaten.per.year,
            data=d, prior="BIC", modelprior=uniform())



nd <- data.frame("yes", "no", 100, 50)
colnames(nd) = colnames(d)

#predict(m.lm, newdata=nd)
dnd = rbind(d, nd)

#model.matrix( ~ likes.cats + likes.dogs + fish.eaten.per.year, data=dnd[101,])  # no errors for model.matrix
# Now predict
pred.m = predict(m, newdata=dnd[100:101,], se=T)  # works
pred.m
```


* * *

## Part 6: Conclusion

